
nname: Auto Sync Simulation Data

on:
  schedule:
    - cron: '0 */6 * * *'  # Runs every 6 hours
  push:
    branches:
      - main
  workflow_dispatch:  # Allow manual triggering

jobs:
  sync:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Add explicit write permissions
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v3
        with:
          fetch-depth: 0  # Fetch all history for all branches and tags

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
       
      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install numpy matplotlib

      - name: Create Data Directory
        run: mkdir -p /home/runner/Documents/simulation_data

      - name: Run Enhanced Simulation
        run: |
          chmod +x src/run_simulation.py
          python src/run_simulation.py /home/runner/Documents/simulation_data
     
      - name: Sync simulation data locally
        run: |
          rsync -av /home/runner/Documents/simulation_data/ /home/runner/Documents/

      - name: Remove Old Data (Retain only last 5 runs)
        run: |
          python -c "
          import os, json, glob
          from datetime import datetime

          # Define the paths
          data_dir = '/home/runner/Documents/simulation_data'
          summary_path = os.path.join(data_dir, 'summary.json')
           
          if not os.path.exists(summary_path):
              exit(0)
           
          # Load summary
          with open(summary_path, 'r') as f:
              summary = json.load(f)
           
          # Get all simulation files
          simulation_files = glob.glob(os.path.join(data_dir, 'simulation_*.json'))
           
          # Group by simulation run
          runs = {}
          for file in simulation_files:
              # Extract timestamp from filename
              parts = file.split('_')
              if len(parts) >= 3:
                  timestamp = parts[-1].replace('.json', '')
                  if timestamp not in runs:
                      runs[timestamp] = []
                  runs[timestamp].append(file)
           
          # Sort timestamps (newest first)
          sorted_timestamps = sorted(runs.keys(), reverse=True)
           
          # Keep only the 5 newest runs
          timestamps_to_keep = sorted_timestamps[:5]
           
          # Remove old files
          deleted_count = 0
          for timestamp, files in runs.items():
              if timestamp not in timestamps_to_keep:
                  for file in files:
                      os.remove(file)
                      deleted_count += 1
                   
          print(f'Removed {deleted_count} old simulation files')
           
          # Update summary
          summary['latest_runs'] = timestamps_to_keep
          with open(summary_path, 'w') as f:
              json.dump(summary, f, indent=2)
          "

      - name: Clean Up
        run: rm -rf /home/runner/Documents/simulation_data
